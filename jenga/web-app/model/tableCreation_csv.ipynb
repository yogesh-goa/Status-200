{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a90020ae-db7c-4a86-bcc4-4c98c46551e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas numpy sdv faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2bbd0c19-783f-4f0c-aad5-177c7728fe4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install numpy pandas Faker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2d4544a9-cc4d-4295-bd24-226009af1f80",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Product_ID  Original_Price  Discounted_Price  Stock_Level  \\\n",
      "count  1430.000000     1430.000000       1430.000000  1430.000000   \n",
      "mean   3668.547552    23690.860434      21569.989273    49.990210   \n",
      "std    1681.325470    30637.893684      28481.266535     6.872622   \n",
      "min    1001.000000      213.400000        213.400000    29.000000   \n",
      "25%    2169.250000     2616.905000       2312.312500    45.000000   \n",
      "50%    3577.000000     8849.165000       8345.320000    50.000000   \n",
      "75%    5139.500000    35597.437500      31376.275000    55.000000   \n",
      "max    6400.000000   195834.100000     195834.100000    70.000000   \n",
      "\n",
      "       Clearance_Flag  \n",
      "count     1430.000000  \n",
      "mean         0.265035  \n",
      "std          0.441506  \n",
      "min          0.000000  \n",
      "25%          0.000000  \n",
      "50%          0.000000  \n",
      "75%          1.000000  \n",
      "max          1.000000  \n",
      "\n",
      "Total Records: 1430\n",
      "\n",
      "Category Distribution:\n",
      "Category\n",
      "Electronics        263\n",
      "Beauty             259\n",
      "Fashion            249\n",
      "Furniture          236\n",
      "Home Appliances    221\n",
      "Books              202\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Subcategory Distribution:\n",
      "Subcategory\n",
      "Jacket             62\n",
      "Sofa               61\n",
      "Smartwatch         61\n",
      "Comics             60\n",
      "Academic           60\n",
      "Refrigerator       59\n",
      "Shampoo            57\n",
      "Air Conditioner    57\n",
      "Hair Dryer         57\n",
      "Sneakers           55\n",
      "Jeans              54\n",
      "Perfume            53\n",
      "Washing Machine    53\n",
      "Smartphone         52\n",
      "Microwave          52\n",
      "Headphone          52\n",
      "Tablet             51\n",
      "Foundation         50\n",
      "Dining Table       48\n",
      "Bed                47\n",
      "Laptop             47\n",
      "Non-Fiction        43\n",
      "Lipstick           42\n",
      "Wardrobe           42\n",
      "T-Shirt            41\n",
      "Fiction            39\n",
      "Chair              38\n",
      "Handbag            37\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "import uuid\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "fake = Faker()\n",
    "\n",
    "# Define the categories and subcategories with product ID ranges and brands\n",
    "categories = {\n",
    "    \"Electronics\": {\n",
    "        \"Headphone\": (1001, 1100, [\"boAt\", \"Sony\", \"JBL\", \"Bose\", \"Noise\", \"Sennheiser\", \"Skullcandy\", \"AKG\", \"Audio-Technica\", \"Philips\"], (1000, 15000)),\n",
    "        \"Smartphone\": (1101, 1200, [\"Apple\", \"Samsung\", \"OnePlus\", \"Xiaomi\", \"POCO\", \"Realme\", \"Vivo\", \"Oppo\", \"Google\", \"Motorola\"], (8000, 80000)),\n",
    "        \"Laptop\": (1201, 1300, [\"Dell\", \"HP\", \"Lenovo\", \"Asus\", \"Acer\", \"MSI\", \"Apple\", \"Microsoft\", \"Alienware\", \"Razer\"], (20000, 150000)),\n",
    "        \"Tablet\": (1301, 1400, [\"Apple\", \"Samsung\", \"Lenovo\", \"Microsoft\", \"Huawei\", \"Amazon\", \"Google\", \"Xiaomi\", \"Realme\", \"Oppo\"], (10000, 60000)),\n",
    "        \"Smartwatch\": (1401, 1500, [\"Apple\", \"Fitbit\", \"Samsung\", \"Amazfit\", \"Garmin\", \"Xiaomi\", \"Fossil\", \"Huawei\", \"Honor\", \"Noise\"], (1999, 50000)),\n",
    "    },\n",
    "    \"Home Appliances\": {\n",
    "        \"Refrigerator\": (2001, 2100, [\"LG\", \"Samsung\", \"Whirlpool\", \"Godrej\", \"Haier\", \"Bosch\", \"IFB\", \"Panasonic\", \"Sharp\", \"Hitachi\"], (15000, 60000)),\n",
    "        \"Washing Machine\": (2101, 2200, [\"IFB\", \"Bosch\", \"Samsung\", \"LG\", \"Whirlpool\", \"Haier\", \"Voltas\", \"Blue Star\", \"Panasonic\", \"Godrej\"], (12000, 50000)),\n",
    "        \"Air Conditioner\": (2201, 2300, [\"Daikin\", \"Voltas\", \"LG\", \"Blue Star\", \"Samsung\", \"Carrier\", \"Hitachi\", \"Panasonic\", \"Haier\", \"Sharp\"], (25000, 75000)),\n",
    "        \"Microwave\": (2301, 2400, [\"IFB\", \"Samsung\", \"LG\", \"Panasonic\", \"Whirlpool\", \"Godrej\", \"Bajaj\", \"Sharp\", \"Haier\", \"Bosch\"], (3000, 25000)),\n",
    "    },\n",
    "    \"Fashion\": {\n",
    "        \"T-Shirt\": (3101, 3200, [\"Levi's\", \"U.S. Polo\", \"Zara\", \"H&M\", \"Nike\", \"Adidas\", \"Puma\", \"Calvin Klein\", \"Tommy Hilfiger\", \"Ralph Lauren\"], (300, 5000)),\n",
    "        \"Jeans\": (3201, 3300, [\"Levi's\", \"Wrangler\", \"Lee\", \"Pepe\", \"Calvin Klein\", \"Tommy Hilfiger\", \"Gap\", \"Diesel\", \"True Religion\", \"G-Star Raw\"], (800, 10000)),\n",
    "        \"Sneakers\": (3301, 3400, [\"Nike\", \"Adidas\", \"Puma\", \"Reebok\", \"Converse\", \"Vans\", \"New Balance\", \"ASICS\", \"Skechers\", \"Under Armour\"], (1000, 15000)),\n",
    "        \"Handbag\": (3401, 3500, [\"Gucci\", \"Louis Vuitton\", \"Coach\", \"Michael Kors\", \"Prada\", \"Chanel\", \"Fendi\", \"Burberry\", \"Tory Burch\", \"Kate Spade\"], (500, 50000)),\n",
    "        \"Jacket\": (3501, 3600, [\"North Face\", \"Adidas\", \"Puma\", \"Columbia\", \"Nike\", \"Under Armour\", \"Patagonia\", \"Arc'teryx\", \"Moncler\", \"Canada Goose\"], (1500, 15000)),\n",
    "    },\n",
    "    \"Beauty\": {\n",
    "        \"Perfume\": (4001, 4100, [\"Chanel\", \"Dior\", \"Gucci\", \"Versace\", \"Tom Ford\", \"Yves Saint Laurent\", \"Prada\", \"Burberry\", \"Calvin Klein\", \"Jean Paul Gaultier\"], (250, 3000)),\n",
    "        \"Lipstick\": (4101, 4200, [\"MAC\", \"Maybelline\", \"L'Oreal\", \"Revlon\", \"Lakme\", \"Colorbar\", \"Faces Canada\", \"NYX\", \"Bobbi Brown\", \"SUGAR\"], (300, 3000)),\n",
    "        \"Foundation\": (4201, 4300, [\"Maybelline\", \"L'Oreal\", \"Revlon\", \"MAC\", \"Lakme\", \"Faces Canada\", \"Bobbi Brown\", \"SUGAR\", \"Colorbar\", \"Estee Lauder\"], (300, 5000)),\n",
    "        \"Hair Dryer\": (4301, 4400, [\"Philips\", \"Panasonic\", \"Havells\", \"Syska\", \"Braun\", \"Vidal Sassoon\", \"Remington\", \"Nova\", \"Wahl\", \"Dyson\"], (800, 10000)),\n",
    "        \"Shampoo\": (4401, 4500, [\"Dove\", \"Head & Shoulders\", \"Pantene\", \"Garnier\", \"L'Oreal\", \"TRESemm√©\", \"Sunsilk\", \"Matrix\", \"Herbal Essences\", \"Himalaya\"], (200, 1000)),\n",
    "    },\n",
    "    \"Furniture\": {\n",
    "        \"Sofa\": (5001, 5100, [\"IKEA\", \"Ashley\", \"La-Z-Boy\", \"Godrej\", \"Urban Ladder\", \"Home Centre\", \"Hometown\", \"Nilkamal\", \"Durian\", \"Royaloak\"], (20000, 200000)),\n",
    "        \"Bed\": (5101, 5200, [\"IKEA\", \"Durian\", \"Springfit\", \"Wakefit\", \"Godrej\", \"Urban Ladder\", \"Home Centre\", \"Hometown\", \"Royaloak\", \"Sleepwell\"], (8000, 100000)),\n",
    "        \"Dining Table\": (5201, 5300, [\"IKEA\", \"Godrej\", \"Urban Ladder\", \"Home Centre\", \"Hometown\", \"Nilkamal\", \"Royaloak\", \"Wood World\", \"Style Spa\", \"Furniturewalla\"], (5000, 10000)),\n",
    "        \"Chair\": (5301, 5400, [\"IKEA\", \"Godrej\", \"Urban Ladder\", \"Home Centre\", \"Hometown\", \"Nilkamal\", \"Royaloak\", \"Featherlite\", \"HOF\", \"Herman Miller\"], (1000, 30000)),\n",
    "        \"Wardrobe\": (5401, 5500, [\"IKEA\", \"Godrej\", \"Urban Ladder\", \"Home Centre\", \"Hometown\", \"Nilkamal\", \"Spacewood\", \"Royaloak\", \"Style Spa\", \"Zuari\"], (10000, 150000)),\n",
    "    },\n",
    "    \"Books\": {\n",
    "        \"Fiction\": (6001, 6100, [\"Penguin\", \"HarperCollins\", \"Simon & Schuster\", \"Random House\", \"Hachette\", \"Pan Macmillan\", \"Bloomsbury\", \"Scholastic\", \"Tor Books\", \"Bantam\"], (200, 1500)),\n",
    "        \"Non-Fiction\": (6101, 6200, [\"Penguin\", \"Hachette\", \"Macmillan\", \"Oxford\", \"Cambridge\", \"Wiley\", \"Pearson\", \"MIT Press\", \"National Geographic\", \"Simon & Schuster\"], (300, 2000)),\n",
    "        \"Academic\": (6201, 6300, [\"Pearson\", \"Wiley\", \"Oxford\", \"Cambridge\", \"McGraw-Hill\", \"Cengage\", \"Routledge\", \"SAGE\", \"Elsevier\", \"Springer\"], (500, 5000)),\n",
    "        \"Comics\": (6301, 6400, [\"Marvel\", \"DC\", \"Image Comics\", \"Dark Horse\", \"IDW Publishing\", \"Boom! Studios\", \"Valiant\", \"Manga\", \"Top Shelf\", \"Fantagraphics\"], (150, 2000)),\n",
    "    },\n",
    "}\n",
    "\n",
    "def generate_product_data(total_records=10000):\n",
    "    \"\"\"\n",
    "    Generate synthetic product data with statistical distributions\n",
    "    \"\"\"\n",
    "    products = []\n",
    "    \n",
    "    for category, subcategories in categories.items():\n",
    "        for subcategory, (start_id, end_id, brands, price_range) in subcategories.items():\n",
    "            # Number of products for each subcategory will vary statistically\n",
    "            num_subcategory_products = np.random.randint(\n",
    "                max(50, (end_id - start_id + 1) // 2), \n",
    "                end_id - start_id + 1\n",
    "            )\n",
    "            \n",
    "            for brand in brands:\n",
    "                for _ in range(num_subcategory_products // len(brands)):\n",
    "                    # Generate Product ID\n",
    "                    product_id = np.random.randint(start_id, end_id + 1)\n",
    "                    \n",
    "                    # Name generation with brand and subcategory\n",
    "                    name = f\"{brand} {subcategory}\"\n",
    "                    \n",
    "                    # Price generation with normal distribution\n",
    "                    original_price = np.random.normal(\n",
    "                        loc=np.mean(price_range), \n",
    "                        scale=(price_range[1] - price_range[0]) / 6\n",
    "                    )\n",
    "                    original_price = max(price_range[0], min(price_range[1], original_price))\n",
    "                    \n",
    "                    # Discount generation\n",
    "                    discount_prob = np.random.random()\n",
    "                    if discount_prob < 0.3:  # 30% chance of discount\n",
    "                        discount_rate = np.random.uniform(0.1, 0.5)\n",
    "                        discounted_price = original_price * (1 - discount_rate)\n",
    "                    else:\n",
    "                        discounted_price = original_price\n",
    "                    \n",
    "                    # Stock level with Poisson distribution\n",
    "                    stock_level = max(0, int(np.random.poisson(50)))\n",
    "                    \n",
    "                    # Clearance flag\n",
    "                    clearance_flag = 1 if stock_level > 20 and discount_prob > 0.7 else 0\n",
    "                    \n",
    "                    # Brand URL generation\n",
    "                    brand_url = f\"https://www.{brand.lower().replace(' ', '')}.com\"\n",
    "                    \n",
    "                    # Description generation\n",
    "                    description = fake.text(max_nb_chars=200)\n",
    "                    \n",
    "                    product = {\n",
    "                        'Product_ID': product_id,\n",
    "                        'Name': name,\n",
    "                        'Category': category,\n",
    "                        'Subcategory': subcategory,\n",
    "                        'Brand': brand,\n",
    "                        'Original_Price': round(original_price, 2),\n",
    "                        'Discounted_Price': round(discounted_price, 2),\n",
    "                        'Stock_Level': stock_level,\n",
    "                        'Clearance_Flag': clearance_flag,\n",
    "                        'Product_URL': brand_url,\n",
    "                        'Description': description\n",
    "                    }\n",
    "                    \n",
    "                    products.append(product)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(products)\n",
    "    \n",
    "    # Ensure unique Product_ID\n",
    "    df = df.drop_duplicates(subset=['Product_ID'])\n",
    "    \n",
    "    return df\n",
    "\n",
    "# Generate the dataset\n",
    "product_df = generate_product_data(total_records=10000)\n",
    "\n",
    "# Basic statistical summary\n",
    "print(product_df.describe())\n",
    "\n",
    "# Save to CSV\n",
    "product_df.to_csv('product_dataset.csv', index=False)\n",
    "\n",
    "# Optional: Quick data validation\n",
    "print(\"\\nTotal Records:\", len(product_df))\n",
    "print(\"\\nCategory Distribution:\")\n",
    "print(product_df['Category'].value_counts())\n",
    "print(\"\\nSubcategory Distribution:\")\n",
    "print(product_df['Subcategory'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6beaae18-b488-404a-a31a-d91bf3bfa727",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Customer Data Summary:\n",
      "       Customer_ID  Cart_Abandonment_Rate\n",
      "count  10000.00000           10000.000000\n",
      "mean    5000.50000              52.476045\n",
      "std     2886.89568              29.019288\n",
      "min        1.00000               2.040000\n",
      "25%     2500.75000              27.270000\n",
      "50%     5000.50000              52.170000\n",
      "75%     7500.25000              78.050000\n",
      "max    10000.00000             100.000000\n",
      "\n",
      "Sales Data Summary:\n",
      "            Sale_ID    Product_ID   Customer_ID  Quantity_Sold       Revenue  \\\n",
      "count  20000.000000  20000.000000  20000.000000   20000.000000  2.000000e+04   \n",
      "mean   10000.500000   3604.108150   4971.947900       2.145000  4.584885e+04   \n",
      "min        1.000000   1001.000000      1.000000       1.000000  2.134000e+02   \n",
      "25%     5000.750000   2133.000000   2456.000000       1.000000  4.244080e+03   \n",
      "50%    10000.500000   3549.000000   4984.000000       2.000000  1.680757e+04   \n",
      "75%    15000.250000   5093.000000   7474.250000       3.000000  5.422140e+04   \n",
      "max    20000.000000   6400.000000  10000.000000       9.000000  1.182366e+06   \n",
      "std     5773.647028   1677.570579   2894.800871       1.267736  7.563096e+04   \n",
      "\n",
      "                       Purchase_Time  \n",
      "count                          20000  \n",
      "mean   2023-09-21 15:45:08.939249920  \n",
      "min              2022-03-29 03:19:25  \n",
      "25%              2022-12-20 22:23:19  \n",
      "50%       2023-09-18 14:09:21.500000  \n",
      "75%    2024-06-21 15:35:14.750000128  \n",
      "max              2025-03-27 23:56:33  \n",
      "std                              NaN  \n",
      "\n",
      "Customer Segment Distribution:\n",
      "Customer_Segment\n",
      "Frequent Shopper    0.3954\n",
      "Budget Buyer        0.2988\n",
      "New Customer        0.2006\n",
      "Premium             0.1052\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Payment Mode Distribution:\n",
      "Payment_Mode\n",
      "Debit Card     0.25325\n",
      "UPI            0.19835\n",
      "Credit Card    0.19635\n",
      "Wallet         0.15110\n",
      "COD            0.14990\n",
      "BNPL           0.05105\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Total Customers: 10000\n",
      "Total Sales Transactions: 20000\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from faker import Faker\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# Set random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "fake = Faker('en_IN')\n",
    "\n",
    "# Predefined segments and payment modes\n",
    "segments = [\"Premium\", \"Budget Buyer\", \"Frequent Shopper\", \"New Customer\"]\n",
    "segment_weights = [0.1, 0.3, 0.4, 0.2]\n",
    "payment_modes = [\"Credit Card\", \"Debit Card\", \"UPI\", \"Wallet\", \"COD\", \"BNPL\"]\n",
    "\n",
    "def generate_indian_locations(num_locations=500):\n",
    "    \"\"\"Generate Indian locations\"\"\"\n",
    "    indian_cities = [\n",
    "        \"Mumbai,Maharashtra,India\", \"Delhi,Delhi,India\", \"Bangalore,Karnataka,India\", \n",
    "        \"Hyderabad,Telangana,India\", \"Chennai,Tamil Nadu,India\", \"Kolkata,West Bengal,India\", \n",
    "        \"Pune,Maharashtra,India\", \"Ahmedabad,Gujarat,India\", \"Jaipur,Rajasthan,India\", \n",
    "        \"Lucknow,Uttar Pradesh,India\", \"Patna,Bihar,India\", \"Chandigarh,Punjab,India\",\n",
    "        \"Bhopal,Madhya Pradesh,India\", \"Kochi,Kerala,India\", \"Guwahati,Assam,India\"\n",
    "    ]\n",
    "    return np.random.choice(indian_cities, num_locations, replace=True)\n",
    "\n",
    "def generate_advanced_purchase_history(product_df):\n",
    "    \"\"\"Generate structured purchase history\"\"\"\n",
    "    num_past_purchases = np.random.choice(\n",
    "        [1, 2, 3, 4, 5], \n",
    "        p=[0.4, 0.3, 0.2, 0.07, 0.03]\n",
    "    )\n",
    "    \n",
    "    purchase_history = []\n",
    "    \n",
    "    for _ in range(num_past_purchases):\n",
    "        product = product_df.sample(1).iloc[0]\n",
    "        \n",
    "        purchase_entry = {\n",
    "            \"product_id\": int(product['Product_ID']),  # Explicitly convert to Python int\n",
    "            \"category\": str(product['Category']),  # Explicitly convert to string\n",
    "            \"subcategory\": str(product['Subcategory']),  # Explicitly convert to string\n",
    "            \"brand\": str(product['Brand']),  # Explicitly convert to string\n",
    "            \"original_price\": float(product['Original_Price']),  # Ensure float\n",
    "            \"discounted_price\": float(product['Discounted_Price']),  # Ensure float\n",
    "            \"purchase_frequency\": int(np.random.choice([1, 2, 3], p=[0.6, 0.3, 0.1])),  # Explicitly convert to int\n",
    "            \"price_sensitivity\": float(round(np.random.uniform(0, 1), 2)),  # Ensure float\n",
    "            \"discount_responsiveness\": float(round(np.random.uniform(0, 1), 2)),  # Ensure float\n",
    "            \"seasonal_purchase\": bool(np.random.choice([True, False], p=[0.3, 0.7])),  # Explicitly convert to bool\n",
    "            \"purchase_timestamp\": fake.date_time_between(start_date='-3y', end_date='now').isoformat()\n",
    "        }\n",
    "        \n",
    "        purchase_history.append(purchase_entry)\n",
    "    \n",
    "    return json.dumps(purchase_history)\n",
    "\n",
    "def calculate_cart_abandonment_rate(total_carts, completed_transactions):\n",
    "    \"\"\"Calculate cart abandonment rate\"\"\"\n",
    "    if total_carts == 0:\n",
    "        return 0\n",
    "    \n",
    "    abandonment_rate = (1 - completed_transactions / total_carts) * 100\n",
    "    return round(max(0, min(abandonment_rate, 100)), 2)\n",
    "\n",
    "def generate_customer_data(product_df, num_customers=10000):\n",
    "    \"\"\"Generate customer data\"\"\"\n",
    "    customers = []\n",
    "    locations = generate_indian_locations(num_customers)\n",
    "    \n",
    "    for i in range(num_customers):\n",
    "         # Customer generation logic\n",
    "        first_digit = np.random.choice([7, 8, 9])\n",
    "        # Generate 9 more random digits after the first digit\n",
    "        remaining_digits = ''.join([str(np.random.randint(0,10)) for _ in range(9)])\n",
    "        phone_number = f\"+91 {first_digit}{remaining_digits}\"\n",
    "        \n",
    "        total_carts = np.random.randint(5, 50)\n",
    "        completed_transactions = np.random.randint(0, total_carts)\n",
    "        \n",
    "        customer_segment = np.random.choice(segments, p=segment_weights)\n",
    "        \n",
    "        customer = {\n",
    "            'Customer_ID': i + 1,\n",
    "            'Location': locations[i],\n",
    "            'Phone_Number': phone_number,\n",
    "            'Purchase_History': generate_advanced_purchase_history(product_df),\n",
    "            'Cart_Abandonment_Rate': calculate_cart_abandonment_rate(total_carts, completed_transactions),\n",
    "            'Customer_Segment': customer_segment\n",
    "        }\n",
    "        \n",
    "        customers.append(customer)\n",
    "    \n",
    "    return pd.DataFrame(customers)\n",
    "\n",
    "def generate_sales_data(customer_df, product_df, num_sales=20000):\n",
    "    \"\"\"\n",
    "    Generate sales data with product selection based on customer's purchase history\n",
    "    \n",
    "    Args:\n",
    "    customer_df (pd.DataFrame): DataFrame of customer data\n",
    "    product_df (pd.DataFrame): DataFrame of product data\n",
    "    num_sales (int): Number of sales to generate\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Sales data with products linked to customer preferences\n",
    "    \"\"\"\n",
    "    sales = []\n",
    "    \n",
    "    # Time range for purchases (last 3 years)\n",
    "    end_date = datetime.now()\n",
    "    start_date = end_date - timedelta(days=3*365)\n",
    "    \n",
    "    for _ in range(num_sales):\n",
    "        # Randomly select customer\n",
    "        customer = customer_df.sample(1).iloc[0]\n",
    "        \n",
    "        # Parse customer's purchase history\n",
    "        purchase_history = json.loads(customer['Purchase_History'])\n",
    "        \n",
    "        # Determine product selection strategy\n",
    "        if purchase_history:\n",
    "            # If customer has purchase history, prioritize similar products\n",
    "            # Option 1: Select from exact previous categories/brands\n",
    "            similar_products = product_df[\n",
    "                (product_df['Category'].isin([ph['category'] for ph in purchase_history])) |\n",
    "                (product_df['Subcategory'].isin([ph['subcategory'] for ph in purchase_history])) |\n",
    "                (product_df['Brand'].isin([ph['brand'] for ph in purchase_history]))\n",
    "            ]\n",
    "            \n",
    "            # If no similar products found, fall back to full product catalog\n",
    "            if similar_products.empty:\n",
    "                similar_products = product_df\n",
    "        else:\n",
    "            # If no purchase history, use full product catalog\n",
    "            similar_products = product_df\n",
    "        \n",
    "        # Select a product\n",
    "        product = similar_products.sample(1).iloc[0]\n",
    "        \n",
    "        # Purchase time with realistic distribution\n",
    "        purchase_time = fake.date_time_between(start_date=start_date, end_date=end_date)\n",
    "        \n",
    "        # Quantity sold with Poisson distribution\n",
    "        quantity = max(1, int(np.random.poisson(2)))\n",
    "        \n",
    "        # Revenue calculation\n",
    "        revenue = product['Discounted_Price'] * quantity\n",
    "        \n",
    "        # Payment mode with weighted probabilities\n",
    "        payment_mode_weights = [0.2, 0.25, 0.2, 0.15, 0.15, 0.05]\n",
    "        payment_mode = np.random.choice(payment_modes, p=payment_mode_weights)\n",
    "        \n",
    "        sale = {\n",
    "            'Sale_ID': _ + 1,\n",
    "            'Product_ID': product['Product_ID'],\n",
    "            'Customer_ID': customer['Customer_ID'],\n",
    "            'Quantity_Sold': quantity,\n",
    "            'Revenue': round(revenue, 2),\n",
    "            'Purchase_Time': purchase_time,\n",
    "            'Payment_Mode': payment_mode\n",
    "        }\n",
    "        \n",
    "        sales.append(sale)\n",
    "    \n",
    "    return pd.DataFrame(sales)\n",
    "\n",
    "# Load product data (assuming it was generated in a previous script)\n",
    "product_df = pd.read_csv('product_dataset.csv')\n",
    "\n",
    "# Generate Customer Data\n",
    "customer_df = generate_customer_data(product_df, num_customers=10000)\n",
    "\n",
    "# Generate Sales Data\n",
    "sales_df = generate_sales_data(customer_df, product_df, num_sales=20000)\n",
    "\n",
    "# Save to separate CSV files\n",
    "customer_df.to_csv('customer_dataset.csv', index=False)\n",
    "sales_df.to_csv('sales_dataset.csv', index=False)\n",
    "\n",
    "# Basic statistical summaries\n",
    "print(\"Customer Data Summary:\")\n",
    "print(customer_df.describe())\n",
    "\n",
    "print(\"\\nSales Data Summary:\")\n",
    "print(sales_df.describe())\n",
    "\n",
    "# Distribution of key features\n",
    "print(\"\\nCustomer Segment Distribution:\")\n",
    "print(customer_df['Customer_Segment'].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nPayment Mode Distribution:\")\n",
    "print(sales_df['Payment_Mode'].value_counts(normalize=True))\n",
    "\n",
    "# Validate the generation\n",
    "print(\"\\nTotal Customers:\", len(customer_df))\n",
    "print(\"Total Sales Transactions:\", len(sales_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "959f13df-ee7b-4765-beef-8ccb4ad37d58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Market Competition Data Overview:\n",
      "        Product_ID   Amazon_Price  Flipkart_Price   Myntra_Price  \\\n",
      "count  1430.000000    1430.000000     1430.000000    1430.000000   \n",
      "mean   3668.547552   21540.349846    21550.979168   21552.495524   \n",
      "std    1681.325470   28531.626258    28543.680640   28323.253638   \n",
      "min    1001.000000     193.890000      217.050000     197.440000   \n",
      "25%    2169.250000    2228.700000     2322.072500    2253.970000   \n",
      "50%    3577.000000    8213.945000     8279.430000    8211.730000   \n",
      "75%    5139.500000   31293.275000    31590.707500   31826.592500   \n",
      "max    6400.000000  209071.870000   189988.640000  193465.610000   \n",
      "\n",
      "          Ajio_Price  Snapdeal_Price  Inflation_Rate  Consumer_Spending_Index  \n",
      "count    1430.000000     1430.000000     1430.000000              1430.000000  \n",
      "mean    21619.868434    21526.587238        0.040499                 0.814657  \n",
      "std     28752.217885    28379.883059        0.008005                 0.341430  \n",
      "min       222.270000      200.950000        0.024000                 0.040000  \n",
      "25%      2305.345000     2253.322500        0.035000                 0.620000  \n",
      "50%      8280.320000     8398.720000        0.040000                 0.890000  \n",
      "75%     31265.335000    31278.092500        0.046000                 1.080000  \n",
      "max    192233.020000   195542.380000        0.060000                 1.300000  \n",
      "\n",
      "Economic Condition Distribution:\n",
      "Economic_Condition\n",
      "Stable       0.416084\n",
      "Growing      0.392308\n",
      "Recession    0.191608\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Inflation Rate Statistics:\n",
      "count    1430.000000\n",
      "mean        0.040499\n",
      "std         0.008005\n",
      "min         0.024000\n",
      "25%         0.035000\n",
      "50%         0.040000\n",
      "75%         0.046000\n",
      "max         0.060000\n",
      "Name: Inflation_Rate, dtype: float64\n",
      "\n",
      "Consumer Spending Index Statistics:\n",
      "count    1430.000000\n",
      "mean        0.814657\n",
      "std         0.341430\n",
      "min         0.040000\n",
      "25%         0.620000\n",
      "50%         0.890000\n",
      "75%         1.080000\n",
      "max         1.300000\n",
      "Name: Consumer_Spending_Index, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "def generate_market_competition_data(product_df, sales_df):\n",
    "    \"\"\"\n",
    "    Generate market and competition data with realistic pricing and economic indicators\n",
    "    \n",
    "    Args:\n",
    "    product_df (pd.DataFrame): Product dataset\n",
    "    sales_df (pd.DataFrame): Sales dataset\n",
    "    \n",
    "    Returns:\n",
    "    pd.DataFrame: Market Competition dataset\n",
    "    \"\"\"\n",
    "    # Economic Condition Probabilities\n",
    "    economic_conditions = ['Growing', 'Stable', 'Recession']\n",
    "    economic_condition_weights = [0.4, 0.4, 0.2]  # More weight to stable and growing economies\n",
    "    \n",
    "    def determine_peak_season(category, subcategory):\n",
    "        \"\"\"\n",
    "        Assign peak seasons with more nuanced, multi-dimensional mapping\n",
    "        \n",
    "        Args:\n",
    "        category (str): Product category\n",
    "        subcategory (str): Product subcategory\n",
    "        \n",
    "        Returns:\n",
    "        tuple: Peak season start and end months\n",
    "        \"\"\"\n",
    "        peak_season_mapping = {\n",
    "            'Electronics': {\n",
    "                'Headphone': [\n",
    "                    {'period': ('September', 'November'), 'reason': 'Festive season, gift purchases'},\n",
    "                    {'period': ('January', 'February'), 'reason': 'New year audio gear sales'}\n",
    "                ],\n",
    "                'Smartphone': [\n",
    "                    {'period': ('September', 'November'), 'reason': 'Festive season, new model launches'},\n",
    "                    {'period': ('January', 'February'), 'reason': 'Republic Day, Budget season sales'}\n",
    "                ],\n",
    "                'Laptop': [\n",
    "                    {'period': ('June', 'July'), 'reason': 'Academic year preparation'},\n",
    "                    {'period': ('October', 'December'), 'reason': 'End-of-year corporate purchases'}\n",
    "                ],\n",
    "                'Tablet': [\n",
    "                    {'period': ('November', 'January'), 'reason': 'Holiday season entertainment'},\n",
    "                    {'period': ('April', 'May'), 'reason': 'Summer travel accessory'}\n",
    "                ],\n",
    "                'Smartwatch': [\n",
    "                    {'period': ('December', 'February'), 'reason': 'New Year fitness resolutions'},\n",
    "                    {'period': ('September', 'October'), 'reason': 'Festive season gifting'}\n",
    "                ]\n",
    "            },\n",
    "            'Home Appliances': {\n",
    "                'Refrigerator': [\n",
    "                    {'period': ('March', 'May'), 'reason': 'Summer preparation, new model launches'},\n",
    "                    {'period': ('August', 'September'), 'reason': 'Festival season home upgrades'}\n",
    "                ],\n",
    "                'Washing Machine': [\n",
    "                    {'period': ('April', 'June'), 'reason': 'Summer home appliance sales'},\n",
    "                    {'period': ('October', 'November'), 'reason': 'Festive season discounts'}\n",
    "                ],\n",
    "                'Air Conditioner': [\n",
    "                    {'period': ('April', 'June'), 'reason': 'Pre-summer cooling solutions'},\n",
    "                    {'period': ('May', 'July'), 'reason': 'Peak summer demand'}\n",
    "                ],\n",
    "                'Microwave': [\n",
    "                    {'period': ('August', 'October'), 'reason': 'Festive season kitchen upgrades'},\n",
    "                    {'period': ('January', 'February'), 'reason': 'New year home cooking trends'}\n",
    "                ]\n",
    "            },\n",
    "            'Fashion': {\n",
    "                'T-Shirt': [\n",
    "                    {'period': ('March', 'May'), 'reason': 'Summer collection launch'},\n",
    "                    {'period': ('September', 'October'), 'reason': 'End of season sales'}\n",
    "                ],\n",
    "                'Jeans': [\n",
    "                    {'period': ('August', 'October'), 'reason': 'Festive season fashion'},\n",
    "                    {'period': ('January', 'February'), 'reason': 'Winter clearance sales'}\n",
    "                ],\n",
    "                'Sneakers': [\n",
    "                    {'period': ('June', 'August'), 'reason': 'Summer sports and fitness'},\n",
    "                    {'period': ('November', 'December'), 'reason': 'Holiday gift season'}\n",
    "                ],\n",
    "                'Handbag': [\n",
    "                    {'period': ('September', 'November'), 'reason': 'Festive season fashion'},\n",
    "                    {'period': ('January', 'February'), 'reason': 'New year style refresh'}\n",
    "                ],\n",
    "                'Jacket': [\n",
    "                    {'period': ('November', 'January'), 'reason': 'Winter wear essential'},\n",
    "                    {'period': ('July', 'August'), 'reason': 'Early winter collection'}\n",
    "                ]\n",
    "            },\n",
    "            'Beauty': {\n",
    "                'Perfume': [\n",
    "                    {'period': ('November', 'January'), 'reason': 'Holiday gifting season'},\n",
    "                    {'period': ('July', 'August'), 'reason': 'Summer fragrance collection'}\n",
    "                ],\n",
    "                'Lipstick': [\n",
    "                    {'period': ('September', 'November'), 'reason': 'Festive makeup trends'},\n",
    "                    {'period': ('January', 'February'), 'reason': 'New year beauty refresh'}\n",
    "                ],\n",
    "                'Foundation': [\n",
    "                    {'period': ('August', 'October'), 'reason': 'Festive season makeup'},\n",
    "                    {'period': ('March', 'April'), 'reason': 'Spring beauty trends'}\n",
    "                ],\n",
    "                'Hair Dryer': [\n",
    "                    {'period': ('June', 'August'), 'reason': 'Summer hair care'},\n",
    "                    {'period': ('November', 'December'), 'reason': 'Holiday personal care gifts'}\n",
    "                ],\n",
    "                'Shampoo': [\n",
    "                    {'period': ('January', 'March'), 'reason': 'Winter hair care'},\n",
    "                    {'period': ('September', 'October'), 'reason': 'Festive season personal care'}\n",
    "                ]\n",
    "            },\n",
    "            'Furniture': {\n",
    "                'Sofa': [\n",
    "                    {'period': ('September', 'November'), 'reason': 'Festive home renovation'},\n",
    "                    {'period': ('January', 'February'), 'reason': 'New year home makeover'}\n",
    "                ],\n",
    "                'Bed': [\n",
    "                    {'period': ('October', 'December'), 'reason': 'Winter bedroom comfort'},\n",
    "                    {'period': ('May', 'June'), 'reason': 'Summer home refresh'}\n",
    "                ],\n",
    "                'Dining Table': [\n",
    "                    {'period': ('August', 'October'), 'reason': 'Festive season home setup'},\n",
    "                    {'period': ('January', 'February'), 'reason': 'New year home improvements'}\n",
    "                ],\n",
    "                'Chair': [\n",
    "                    {'period': ('July', 'September'), 'reason': 'Home office setup'},\n",
    "                    {'period': ('November', 'December'), 'reason': 'Holiday home furnishing'}\n",
    "                ],\n",
    "                'Wardrobe': [\n",
    "                    {'period': ('November', 'January'), 'reason': 'Festive season home organization'},\n",
    "                    {'period': ('April', 'May'), 'reason': 'Summer home renovation'}\n",
    "                ]\n",
    "            },\n",
    "            'Books': {\n",
    "                'Fiction': [\n",
    "                    {'period': ('October', 'December'), 'reason': 'Holiday reading season'},\n",
    "                    {'period': ('June', 'July'), 'reason': 'Summer vacation reading'}\n",
    "                ],\n",
    "                'Non-Fiction': [\n",
    "                    {'period': ('June', 'August'), 'reason': 'Summer learning and development'},\n",
    "                    {'period': ('January', 'February'), 'reason': 'New year personal growth'}\n",
    "                ],\n",
    "                'Academic': [\n",
    "                    {'period': ('May', 'July'), 'reason': 'Academic year preparation'},\n",
    "                    {'period': ('December', 'January'), 'reason': 'Mid-year academic supplements'}\n",
    "                ],\n",
    "                'Comics': [\n",
    "                    {'period': ('November', 'January'), 'reason': 'Holiday gift season'},\n",
    "                    {'period': ('July', 'August'), 'reason': 'Summer entertainment'}\n",
    "                ]\n",
    "            }\n",
    "        }\n",
    "        \n",
    "        # Return peak seasons for the specific subcategory if exists\n",
    "        if category in peak_season_mapping and subcategory in peak_season_mapping[category]:\n",
    "            return peak_season_mapping[category][subcategory][0]['period']\n",
    "        \n",
    "        # Fallback to first period in the category\n",
    "        if category in peak_season_mapping:\n",
    "            first_subcategory = list(peak_season_mapping[category].keys())[0]\n",
    "            return peak_season_mapping[category][first_subcategory][0]['period']\n",
    "        \n",
    "        # Default fallback\n",
    "        return ('January', 'March')\n",
    "\n",
    "    # Rest of the function remains the same as in the previous version\n",
    "    market_competition_data = []\n",
    "    \n",
    "    for _, product in product_df.iterrows():\n",
    "        # Calculate total revenue for this product\n",
    "        product_sales = sales_df[sales_df['Product_ID'] == product['Product_ID']]\n",
    "        total_product_revenue = product_sales['Revenue'].sum() if not product_sales.empty else 10000\n",
    "        \n",
    "        # Base price calculation with competitor pricing\n",
    "        base_price = product['Discounted_Price']\n",
    "        \n",
    "        # Competitor pricing strategy\n",
    "        # Slight variations around base price with probabilistic adjustments\n",
    "        amazon_price = round(base_price * np.random.uniform(0.9, 1.1), 2)\n",
    "        flipkart_price = round(base_price * np.random.uniform(0.9, 1.1), 2)\n",
    "        myntra_price = round(base_price * np.random.uniform(0.9, 1.1), 2)\n",
    "        ajio_price = round(base_price * np.random.uniform(0.9, 1.1), 2)\n",
    "        snapdeal_price = round(base_price * np.random.uniform(0.9, 1.1), 2)\n",
    "        \n",
    "        # Inflation and Consumer Spending Index based on product category and revenue\n",
    "        category_inflation_base = {\n",
    "            \"Electronics\": 0.05,\n",
    "            \"Home Appliances\": 0.04,\n",
    "            \"Fashion\": 0.045,\n",
    "            \"Beauty\": 0.035,\n",
    "            \"Furniture\": 0.04,\n",
    "            \"Books\": 0.03\n",
    "        }\n",
    "        \n",
    "        # Inflation calculation\n",
    "        base_inflation = category_inflation_base.get(product['Category'], 0.04)\n",
    "        inflation_rate = round(base_inflation * (1 + np.random.uniform(-0.2, 0.2)), 3)\n",
    "        \n",
    "        # Consumer Spending Index\n",
    "        # Higher index for high-revenue products and growing economic conditions\n",
    "        consumer_spending_base = min(total_product_revenue / 100000, 1)  # Normalize revenue impact\n",
    "        consumer_spending_index = round(consumer_spending_base * np.random.uniform(0.7, 1.3), 2)\n",
    "        \n",
    "        # Peak Season Determination\n",
    "        peak_start, peak_end = determine_peak_season(product['Category'], product['Subcategory'])\n",
    "        \n",
    "        # Economic Condition\n",
    "        economic_condition = np.random.choice(\n",
    "            economic_conditions, \n",
    "            p=economic_condition_weights\n",
    "        )\n",
    "        \n",
    "        market_competition_entry = {\n",
    "            'Product_ID': product['Product_ID'],\n",
    "            'Category': product['Category'],\n",
    "            'Subcategory': product['Subcategory'],\n",
    "            'Amazon_Price': amazon_price,\n",
    "            'Flipkart_Price': flipkart_price,\n",
    "            'Myntra_Price': myntra_price,\n",
    "            'Ajio_Price': ajio_price,\n",
    "            'Snapdeal_Price': snapdeal_price,\n",
    "            'Peak_Season_Start': peak_start,\n",
    "            'Peak_Season_End': peak_end,\n",
    "            'Inflation_Rate': inflation_rate,\n",
    "            'Consumer_Spending_Index': consumer_spending_index,\n",
    "            'Economic_Condition': economic_condition\n",
    "        }\n",
    "        \n",
    "        market_competition_data.append(market_competition_entry)\n",
    "    \n",
    "    return pd.DataFrame(market_competition_data)\n",
    "\n",
    "market_competition_df = generate_market_competition_data(product_df, sales_df)\n",
    "market_competition_df.to_csv('market_competition_dataset.csv', index=False)\n",
    "\n",
    "# Print some statistics for verification\n",
    "print(\"\\nMarket Competition Data Overview:\")\n",
    "print(market_competition_df.describe())\n",
    "\n",
    "print(\"\\nEconomic Condition Distribution:\")\n",
    "print(market_competition_df['Economic_Condition'].value_counts(normalize=True))\n",
    "\n",
    "print(\"\\nInflation Rate Statistics:\")\n",
    "print(market_competition_df['Inflation_Rate'].describe())\n",
    "\n",
    "print(\"\\nConsumer Spending Index Statistics:\")\n",
    "print(market_competition_df['Consumer_Spending_Index'].describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "329d5807-2c9b-41c6-b302-5350025a7db9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e665e7fb-c331-4d5f-9bd7-181badf8085a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
